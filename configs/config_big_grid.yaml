agent:
  actions:
    - UP
    - DOWN
    - LEFT
    - RIGHT
    - STAY
  properties:
    observation_offset: 1 # either a number between 0 and 1, or a random, or none for 0
    transition_offset: 0 # either a number between 0 and 1, or a random, or none for 0
  init_state: null
environment:
  grid_dimensions: [9, 9]
  initial_position: null #(0,0)
  complexities:
    obstacles: null #  [[1,1], [1,2], [2, 1]] # None
    cues: null #[(1,1), (1, 7), (6, 1), (6, 7)] # could be defined list or None
#      - cue1:
#        location: (1,1)
#        trigger: positive
  terminal_states:
    Goal: [4, 4]
    Trap: null #[2, 4]
experiment_parameters:
  global:
    time_steps: [75, 125, 175]
    test_name: "9_by_9_grid_experiment"
    trap: False
    verbosity: False
    gen_model:
      noisy_observation: 0.1
      noisy_transition: 0.1
      noisy_start: True
#    environment:
#      changing_obstacles: False
#      changing_cues: False
  RF:
    gamma: 5
  AiF:
    gamma: [8, 16, 32]
    alpha: [8, 16,32]
    agent_class:
      stochastic_short_policy:
        sampling_mode: "marginal"
        policy_len: 3
        agent_selection: "stochastic"
      stochastic_long_policy:
          sampling_mode: "marginal"
          policy_len: 4
          agent_selection: "stochastic"
      stochastic_long_long_policy:
        sampling_mode: "marginal"
        policy_len: 5
        agent_selection: "stochastic"
#      deterministic_long_policy:
#        sampling_mode: "full"
#        policy_len: 6
#        agent_selection: "deterministic"
    # For things below, not sure if they do much
    use_states_info_gain: True
    use_utility: True
    policy_sep_prior: False # cant be true with use_BMA
    use_BMA: True # cant be true with policy_sep_prior
    use_param_info_gain: True
model_derivation:
  None




