
agent:
  actions:
    - UP
    - DOWN
    - LEFT
    - RIGHT
    - STAY
  properties:
    observation_offset: 1 # either a number between 0 and 1, or a random, or none for 0
    transition_offset: 0 # either a number between 0 and 1, or a random, or none for 0
environment:
  grid_dimensions: [5, 5]
  initial_position: None #(0,0)
  complexities:
    obstacles: None # [(1,2), (2,2)]
    cues: None #[(1,1), (1, 7), (6, 1), (6, 7)] # could be defined list or None
#      - cue1:
#        location: (1,1)
#        trigger: positive
  terminal_states:
    Goal: [2, 2]
    Trap: [2, 4]

experiment_parameters:
  global:
    time_steps: [25]
    save_name: "simple_grid_world"
    trap: False
    verbosity: False
    gen_model:
      noisy_observation: 0.1
      noisy_transition: 0.1
      noisy_start: True
#    environment:
#      changing_obstacles: False
#      changing_cues: False
  RF:
    gamma: 5
  AiF:
    gamma: [8, 16, 32]
    alpha: [8, 16, 32]
    agent_class:
#      stochastic_short_policy:
#        sampling_mode: "marginal"
#        policy_len: 2
#        agent_selection: "stochastic"
#      stochastic_long_policy:
#          sampling_mode: "marginal"
#          policy_len: 4
#          agent_selection: "stochastic"
      deterministic_long_policy:
        sampling_mode: "full"
        policy_len: 4
        agent_selection: "deterministic"
#    sampling_mode: ["full", "marginal"] # either full or marginal
#    policy_len:
#      stochastic: [2, 4]
#      deterministic: [4]
#    agent_selection: ["stochastic", "deterministic"] # Either deterministic of stochastic
    # For things below, not sure if they do much
    use_states_info_gain: True
    use_utility: True
    policy_sep_prior: False # cant be true with use_BMA
    use_BMA: True # cant be true with policy_sep_prior
    use_param_info_gain: True
model_derivation:
  None




